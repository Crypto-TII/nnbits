# N-BEATS in Cryptanalysis | Distinguish Random Data from a Cipher Output

_(This work has been submitted to JOURNAL and is currently under review)_

This is the code related to â€¦

This repository contains the following files:
```
NBEATS-Cipher-Distinguisher
|   |   README.md               <- the file which generates the current view
|   |_
|_  demo.ipynb                  <- demo notebook
|_  distinguisher
    |_  define_ensemble.py      <- defines an ensemble of N-BEATS (see `Methodology` and `Commands to Execute` below) 
    |_  ensemble.py             <- trains or tests an ensemble of N-BEATS (see `Methodology` and `Commands to Execute` below)
    |_  analyze_ensemble.py     <- performs an analysis of the test-data (see `Methodology` and `Commands to Execute` below) 
    |_  utils                   <- contains files for dataset creation, file management, plot style, setting random seeds
```

A demo is available in Google Colab

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github//Crypto-TII/nbeats_statistical_test/demo.ipynb)

# Introduction 

The state-of-the-art (SOTA)
----
* NIST statistical tests _"Name of paper"_  ([Paper](https://))
* DIE-HARD(ER) statistical tests _"Name of paper"_  ([Paper](https://))
* Avalanche test _"Name of paper"_  ([Paper](https://)) 
* Gohr's deep neural networks distinguisher _"Improving Attacks on Round-Reduced Speck32/64 Using Deep Learning"_  ([Paper](https://doi.org/10.1007/978-3-030-26951-7_6.))
* Machine learning & NIST as cryptographic distinguisher  _"Name of paper"_  ([Paper](https://))


Methodology 
----

An ensemble of deep neural networks is trained and tested on a `*.npy` file which contains sequences of potential random data.  

1. Each ensemble member is defined by a dedicated configuration `*.cfg` file 
2. Each ensemble member is trained on the training data as defined in the `*.cfg` file 
3. Each ensemble member is tested on the test data as defined in the `*.cfg` file 
4. An analysis on the bit-level is performed on the test outcomes

# Commands to Execute

Assuming the data to be tested is located in `{data_path}`, 
please run the following minimal set of commands:

1. Create the `*.cfg` files
```shell
python -m distinguisher.define_ensemble --data_path '{data_path}' --save_path '{save_path}'
``` 
2. Train the ensemble
```shell
python -m distinguisher.ensemble -mode train --save_path '{save_path}'
``` 
3. Test the ensemble
```shell
python -m distinguisher.ensemble -mode test --save_path '{save_path}'
``` 
4. Analyze the outcome 
```shell
python -m distinguisher.analyze_ensemble --save_path '{save_path}'
```

Running these commands will create a folder located in path `save_path` with the following structure
```
save_path
    |_  cfg             <- *.cfg ensemble configuration files (generated by calling define_ensemble.py)
    |_  h5              <- *.h5 neural network model files (generated by calling train_ensemble.py)
    |_  hist            <- *.pkl files which contain the training history of each ensemble member 
    |_  pred            <- *.npy files with the predictions of each ensemble member (generated by running test_ensemble.py)
```

# Notes

## Expected Data Format
The `{data_path}` contains a single `*.npy` file with X sequences of length 1024 bits for SPECK 32/64, for example:
```python 
>>> filename = '/home/anna/NBEATSD4/data_5rounds_1000000_samples.npy'
>>> data = np.load(filename)
>>> print(data.shape)
(1000000, 1024) # 1'000'000 rows with n_bits=1024 in each row.
>>> print(data[0])
array([0, 0, 0, ..., 1, 0, 1], dtype=uint8)
```

# Citation
If you use this code in your work, please cite the following [paper]()
```
@inproceedings{

}
```
